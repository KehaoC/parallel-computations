# Lab 11: GPU加速的卷积操作实现

## 实验概述
本实验主要实现三种卷积操作的GPU加速方法，并对比它们的性能：
1. 直接卷积（滑窗法）
2. im2col + GEMM方法
3. cuDNN库实现

## 实验要求
- 实现2D卷积操作，输入和卷积核都有3个通道
- 卷积核大小固定为3×3
- 测试不同步幅(stride=1,2,3)
- 根据需要添加padding
- 不考虑bias(设为0)
- 输入尺寸从小到大测试(如从32×32到512×512)

## 实验分析

### 任务1：直接卷积（滑窗法）
直接卷积是最直观的实现方式，通过滑动窗口在输入上移动卷积核，计算每个位置的卷积结果。

实现思路：
- 为每个输出位置分配一个CUDA线程
- 每个线程负责计算一个输出元素，通过遍历对应的输入区域和卷积核
- 考虑padding和stride的处理

### 任务2：im2col + GEMM方法
im2col方法将卷积操作转换为矩阵乘法，可以充分利用GPU的矩阵乘法优化。

实现思路：
- 使用im2col将输入数据重排为列矩阵
- 将卷积核重排为行矩阵
- 使用之前实现的GEMM(通用矩阵乘法)进行计算
- 将结果重塑为正确的输出维度

### 任务3：cuDNN实现
使用NVIDIA提供的cuDNN库实现卷积操作，作为性能基准。

实现思路：
- 调用cuDNN API设置卷积参数
- 测量执行时间
- 与前两种方法进行性能对比

## 实现计划

1. 搭建基本框架
   - 创建数据生成和验证函数
   - 实现计时功能
   - 设计测试流程

2. 实现直接卷积
   - 编写CUDA核函数处理不同stride和padding
   - 优化线程块和网格配置

3. 实现im2col + GEMM方法
   - 编写im2col函数
   - 复用或修改之前的GEMM实现
   - 整合为完整的卷积操作

4. 实现cuDNN版本
   - 配置cuDNN环境
   - 实现cuDNN卷积接口调用

5. 性能测试与分析
   - 测试不同输入大小(32×32到512×512)
   - 测试不同stride(1,2,3)
   - 记录并比较三种方法的执行时间
   - 分析性能差异原因

## 预期输出
- 三种方法的卷积结果
- 不同输入大小和stride下的执行时间对比
- 性能分析和可能的优化方向 